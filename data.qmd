# Data

## Data Collection

The dataset for this project was collected from the Federal Reserve Economic Data (FRED) database, which provides comprehensive macroeconomic and financial time series data. The data collection process involved downloading multiple time series covering:

### Data Sources

1.  **Treasury Yield Curve Data**: Constant maturity rates for various maturities (3-month, 1-year, 2-year, 5-year, 7-year, 10-year, 20-year, 30-year)
2.  **Recession Indicators**: NBER-defined recession periods (USREC, USRECM)
3.  **Inflation Measures**:
    -   Consumer Price Index (CPI): Headline, Core, Energy, Food & Beverages
    -   Personal Consumption Expenditures (PCE): Headline and Core
    -   Producer Price Index (PPI): Final Demand, Energy, Commodities
4.  **Unemployment Data**:
    -   Aggregate unemployment rate
    -   By gender (Men, Women)
    -   By race/ethnicity (White, Black, Hispanic)
    -   By age groups (16-19, 20-24, 25-54, 55+)
5.  **Inflation Expectations**:
    -   Market-based (TIPS breakeven rates)
    -   Survey-based (University of Michigan)
6.  **Commodity Prices**: WTI Crude Oil
7.  **Labor Costs**: Employment Cost Index

### Collection Method

Data was downloaded programmatically using Python scripts that accessed FRED's public CSV download endpoints. The collection script (`data_collection.py`) downloaded 42 different time series, with some series unavailable or discontinued.

```{r}
#| setup: true
#| include: false
#| warning: false
#| message: false
library(tidyverse)
library(janitor)
library(here)
library(DT)
library(scales)
library(patchwork)
library(corrplot)
library(gt)

# Load cleaned master dataset
master <- read_csv("data/clean/master_df.csv") |>
  clean_names() |>
  mutate(date = as.Date(date))
```

## Data Cleaning and Processing

### Initial Data Structure

The raw data files were stored as individual CSV files in the `data/raw/` directory, with each file containing a single time series from FRED. The files were then merged into a unified master dataset through the `data_cleaning.py` script

### Cleaning Steps

1.  **Date Alignment**: All series were merged on the date column, creating a monthly frequency dataset
2.  **Time Period Selection**: Data was filtered to start from January 1954, when most macroeconomic series become available
3.  **Missing Value Handling**:
    -   Series with more than 95% missing values were excluded
    -   Treasury yield series (DGS\*) were forward-filled (carried forward) to handle temporary gaps
    -   Macroeconomic series were forward-filled to maintain continuity
    -   Recession indicator (USREC) was filled with 0 for non-recession periods
4.  **Final Dataset**: After cleaning, the master dataset contains 863 monthly observations and 35 variables

```{r}
# Dataset summary statistics
cat(sprintf(
  "Dataset Dimensions:\nRows (months): %d\nColumns (variables): %d\n\nDate Range:\nStart: %s\nEnd:   %s\nSpan:  %.2f years\n",
  nrow(master),
  ncol(master),
  as.character(min(master$date)),
  as.character(max(master$date)),
  as.numeric(max(master$date) - min(master$date)) / 365.25
))
```

### Missing Value Analysis

```{r}
# Calculate missing value statistics
missing_stats <- master |>
  summarise(across(everything(), ~ sum(is.na(.x)))) |>
  pivot_longer(everything(), names_to = "variable", values_to = "missing_count") |>
  mutate(
    missing_pct = (missing_count / nrow(master)) * 100,
    variable_clean = case_when(
      variable == "dgs3mo" ~ "3-Month Treasury",
      variable == "dgs1" ~ "1-Year Treasury",
      variable == "dgs2" ~ "2-Year Treasury",
      variable == "dgs5" ~ "5-Year Treasury",
      variable == "dgs7" ~ "7-Year Treasury",
      variable == "dgs10" ~ "10-Year Treasury",
      variable == "dgs20" ~ "20-Year Treasury",
      variable == "dgs30" ~ "30-Year Treasury",
      variable == "usrec" ~ "Recession Indicator",
      variable == "usrecm" ~ "Recession Indicator (Alt)",
      variable == "cpiaucsl" ~ "CPI Headline",
      variable == "cpilfesl" ~ "CPI Core",
      variable == "cpiengsl" ~ "CPI Energy",
      variable == "cpifabsl" ~ "CPI Food",
      variable == "pcepi" ~ "PCE Headline",
      variable == "pcepilfe" ~ "PCE Core",
      variable == "ppifgs" ~ "PPI Final Demand",
      variable == "ppieng" ~ "PPI Energy",
      variable == "ppicmm" ~ "PPI Commodities",
      variable == "unrate" ~ "Unemployment Rate",
      variable == "lns14000001" ~ "Unemp: Men",
      variable == "lns14000002" ~ "Unemp: Women",
      variable == "lns14000003" ~ "Unemp: White",
      variable == "lns14000006" ~ "Unemp: Black",
      variable == "lns14000009" ~ "Unemp: Hispanic",
      variable == "lns14000012" ~ "Unemp: 16-19",
      variable == "lns14000089" ~ "Unemp: 20-24",
      variable == "lns14000025" ~ "Unemp: 25-54",
      variable == "lns14000036" ~ "Unemp: 55+",
      variable == "t5yie" ~ "5Y Breakeven",
      variable == "t10yie" ~ "10Y Breakeven",
      variable == "t5yifr" ~ "5Y Forward",
      variable == "mich" ~ "Michigan Survey",
      variable == "dcoilwtico" ~ "WTI Oil",
      variable == "eciallciv" ~ "Employment Cost Index",
      TRUE ~ variable
    )
  ) |>
  arrange(desc(missing_pct))

# Plot missing values
ggplot(missing_stats, aes(x = reorder(variable_clean, missing_pct), y = missing_pct)) +
  geom_col(fill = "steelblue", alpha = 0.8) +
  coord_flip() +
  labs(
    title = "Missing Values by Variable",
    subtitle = "Percentage of missing observations in master dataset",
    x = "Variable",
    y = "Missing Percentage (%)"
  ) +
  theme_minimal(base_size = 11) +
  theme(
    panel.grid.minor = element_blank(),
    axis.text.y = element_text(size = 8)
  )
```

**Inference:** Most variables have complete or near-complete data, which is great for analysis. The ones with higher missing percentages like TIPS breakeven rates (T10YIE, T5YIE, T5YIFR) and the Employment Cost Index are newer series that simply weren't collected in earlier decades. This makes sense historically; TIPS didn't exist until the late 1990s, and the ECI started in the 1980s. The oil price data (DCOILWTICO) also has gaps, likely due to market disruptions or data collection issues. For our analysis, we'll focus on variables with good coverage, and when we need the newer series, we'll work with the available time periods.

## Dataset Overview

### Variable Categories

The master dataset contains the following categories of variables:

1.  **Treasury Yields** (8 variables): DGS3MO, DGS1, DGS2, DGS5, DGS7, DGS10, DGS20, DGS30
2.  **Recession Indicators** (2 variables): USREC, USRECM
3.  **Inflation Measures** (9 variables): CPI (headline, core, energy, food), PCE (headline, core), PPI (final demand, energy, commodities)
4.  **Unemployment** (10 variables): Total, by gender (2), by race (3), by age (4)
5.  **Inflation Expectations** (4 variables): T5YIE, T10YIE, T5YIFR, MICH
6.  **Commodities** (1 variable): DCOILWTICO
7.  **Labor Costs** (1 variable): ECIALLCIV

### Time Series Coverage

```{r}
# Create Cleveland dot plot showing when each variable has data (ALL variables)
coverage_data <- master |>
  summarise(across(-date, ~ min(date[!is.na(.x)]), .names = "start_{.col}")) |>
  pivot_longer(everything(), names_to = "variable", values_to = "start_date") |>
  mutate(
    variable = str_remove(variable, "start_"),
    variable_clean = case_when(
      variable == "dgs3mo" ~ "3-Month Treasury",
      variable == "dgs1" ~ "1-Year Treasury",
      variable == "dgs2" ~ "2-Year Treasury",
      variable == "dgs5" ~ "5-Year Treasury",
      variable == "dgs7" ~ "7-Year Treasury",
      variable == "dgs10" ~ "10-Year Treasury",
      variable == "dgs20" ~ "20-Year Treasury",
      variable == "dgs30" ~ "30-Year Treasury",
      variable == "usrec" ~ "Recession Indicator",
      variable == "usrecm" ~ "Recession Indicator (Alt)",
      variable == "cpiaucsl" ~ "CPI Headline",
      variable == "cpilfesl" ~ "CPI Core",
      variable == "cpiengsl" ~ "CPI Energy",
      variable == "cpifabsl" ~ "CPI Food",
      variable == "pcepi" ~ "PCE Headline",
      variable == "pcepilfe" ~ "PCE Core",
      variable == "ppifgs" ~ "PPI Final Demand",
      variable == "ppieng" ~ "PPI Energy",
      variable == "ppicmm" ~ "PPI Commodities",
      variable == "unrate" ~ "Unemployment Rate",
      variable == "lns14000001" ~ "Unemployment: Men",
      variable == "lns14000002" ~ "Unemployment: Women",
      variable == "lns14000003" ~ "Unemployment: White",
      variable == "lns14000006" ~ "Unemployment: Black",
      variable == "lns14000009" ~ "Unemployment: Hispanic",
      variable == "lns14000012" ~ "Unemployment: 16-19",
      variable == "lns14000089" ~ "Unemployment: 20-24",
      variable == "lns14000025" ~ "Unemployment: 25-54",
      variable == "lns14000036" ~ "Unemployment: 55+",
      variable == "t5yie" ~ "5-Year Breakeven",
      variable == "t10yie" ~ "10-Year Breakeven",
      variable == "t5yifr" ~ "5-Year Forward",
      variable == "mich" ~ "Michigan Survey",
      variable == "dcoilwtico" ~ "WTI Oil",
      variable == "eciallciv" ~ "Employment Cost Index",
      TRUE ~ variable
    )
  ) |>
  arrange(start_date)

# Cleveland dot plot
ggplot(coverage_data, aes(x = start_date, y = reorder(variable_clean, start_date))) +
  geom_point(size = 2, colour = "steelblue") +
  geom_segment(aes(x = start_date, xend = start_date, y = reorder(variable_clean, start_date), yend = reorder(variable_clean, start_date)), 
               colour = "steelblue", linewidth = 0.3) +
  labs(
    title = "Data Availability Start Dates for All Variables",
    subtitle = "Shows when each variable first has non-missing data",
    x = "Start Date",
    y = NULL
  ) +
  theme_minimal(base_size = 11) +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_line(colour = "grey90"),
    axis.text.y = element_text(size = 7)
  )
```

**Inference:** This Cleveland dot plot shows when each variable starts having data. Most of our core series (unemployment, CPI, and Treasury yields) begin around 1954. Newer series like TIPS break-even rates and the Employment Cost Index start much later, which explains their higher missing percentages.

### Distribution of Key Variables

```{r}
# Distribution plots for key variables with normal distribution curves
# 10-Year Treasury Yield
dgs10_data <- master |> filter(!is.na(dgs10))
dgs10_mean <- mean(dgs10_data$dgs10, na.rm = TRUE)
dgs10_sd <- sd(dgs10_data$dgs10, na.rm = TRUE)

p1 <- master |>
  ggplot(aes(x = dgs10)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = "steelblue", alpha = 0.7) +
  stat_function(fun = dnorm, args = list(mean = dgs10_mean, sd = dgs10_sd), 
                colour = "darkblue", linewidth = 1) +
  labs(title = "10-Year Treasury Yield", x = "Yield (%)", y = "Density") +
  theme_minimal()

# Unemployment Rate
unrate_mean <- mean(master$unrate, na.rm = TRUE)
unrate_sd <- sd(master$unrate, na.rm = TRUE)

p2 <- master |>
  ggplot(aes(x = unrate)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = "darkgreen", alpha = 0.7) +
  stat_function(fun = dnorm, args = list(mean = unrate_mean, sd = unrate_sd), 
                colour = "darkgreen", linewidth = 1) +
  labs(title = "Unemployment Rate", x = "Rate (%)", y = "Density") +
  theme_minimal()

# CPI Year-over-Year Inflation
cpi_yoy_data <- master |>
  filter(!is.na(cpiaucsl)) |>
  mutate(cpi_yoy = (cpiaucsl / lag(cpiaucsl, 12) - 1) * 100) |>
  filter(!is.na(cpi_yoy))
cpi_yoy_mean <- mean(cpi_yoy_data$cpi_yoy, na.rm = TRUE)
cpi_yoy_sd <- sd(cpi_yoy_data$cpi_yoy, na.rm = TRUE)

p3 <- cpi_yoy_data |>
  ggplot(aes(x = cpi_yoy)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = "darkred", alpha = 0.7) +
  stat_function(fun = dnorm, args = list(mean = cpi_yoy_mean, sd = cpi_yoy_sd), 
                colour = "darkred", linewidth = 1) +
  labs(title = "CPI Year-over-Year Inflation", x = "Inflation (%)", y = "Density") +
  theme_minimal()

p1 / p2 / p3
```

**Inference:** These histograms give us a quick sense of what "normal" looks like for our key variables. The 10-year Treasury yield is pretty spread out, ranging from near zero (recent years) to over 15% (early 1980s), with most values clustering around 4-6%. Unemployment shows a right-skewed distribution most of the time it's below 6%, but we do see those painful spikes during recessions. The inflation distribution is interesting too; it's centered around 2-3% but has a long tail on the right from those high-inflation periods in the 1970s and early 1980s. This tells us our dataset captures both normal times and extreme events, which is exactly what we need.

### Correlation Matrix of Key Variables

```{r}
# Calculate correlations for key variables
cor_vars <- c("dgs10", "dgs2", "dgs3mo", "unrate", "cpiaucsl", "cpilfesl")
cor_data <- master |>
  select(all_of(cor_vars)) |>
  cor(use = "pairwise.complete.obs")

# Create full names for labels
full_names <- c(
  "dgs10" = "10-Year Treasury Yield",
  "dgs2" = "2-Year Treasury Yield",
  "dgs3mo" = "3-Month Treasury Yield",
  "unrate" = "Unemployment Rate",
  "cpiaucsl" = "CPI Headline",
  "cpilfesl" = "CPI Core"
)

# Rename rows and columns
rownames(cor_data) <- full_names[rownames(cor_data)]
colnames(cor_data) <- full_names[colnames(cor_data)]

# Create correlation plot with same orientation on both axes
corrplot(
  cor_data,
  method = "color",
  type = "full",
  order = "hclust",
  tl.cex = 0.8,
  tl.col = "black",
  tl.srt = 45,  # Rotate labels 45 degrees
  addCoef.col = "black",
  number.cex = 0.7,
  diag = TRUE
)
```

The correlation matrix reveals some expected relationships. Treasury yields at different maturities are highly correlated (0.8-0.9), which makes sense as they're all responding to similar economic forces. CPI headline and core are very closely related (0.99), as expected. Interestingly, yields and inflation show moderate positive correlation, which could reinforce the idea that higher inflation expectations push bond yields up. What's also interesting is that we don't see strong negative correlations here unemployment doesn't correlate strongly with yields or inflation in this simple view, but that's probably because the relationship is more complex and time-varying. The **Phillips curve** relationship (negative correlation between unemployment and inflation) might be masked by the long time period or might only appear during specific economic regimes. The clustering in the plot groups similar variables together, which helps us understand the structure of our data.

## Data Processing Notes

### Forward-Filling Strategy

The cleaning process used forward-filling (carry-forward) for missing values, which is appropriate for time series data where treasury yields are relatively stable month-to-month, macroeconomic indicators change gradually & missing values often represent temporary data collection gaps rather than true missing observations

### Limitations

1.  **Early Period Coverage**: Some series (e.g., TIPS breakeven rates, some demographic unemployment data) have limited historical coverage
2.  **Frequency**: All data is monthly, which may miss higher-frequency dynamics
3.  **Missing Data**: Some variables (e.g., Employment Cost Index) have significant gaps, limiting their use in time series analysis
4.  **Data Availability**: Some originally planned series (e.g., GSCPI, certain CPI/PCE components) were unavailable from FRED

### Final Dataset

The cleaned master dataset (`master_df.csv`) is saved in the `data/clean/` directory and serves as the primary data source for all analyses in this project.
